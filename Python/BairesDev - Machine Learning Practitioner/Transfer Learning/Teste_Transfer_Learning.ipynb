{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/HuugoAlexandre/Digital-Innovation-One/blob/main/Teste_Transfer_Learning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "# Muda o diretório de trabalho para '/content' (onde o colab tem permissão pra gravar)\n",
        "os.chdir('/content')\n"
      ],
      "metadata": {
        "id": "FdjsWLfwA4hr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://download.microsoft.com/download/3/E/1/3E1C3F21-ECDB-4869-8368-6DEBA77B919F/kagglecatsanddogs_5340.zip"
      ],
      "metadata": {
        "id": "j5NIxb6IA7Gn",
        "outputId": "178f16d9-403d-4886-eb90-2d274983c4df",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2024-12-21 21:47:35--  https://download.microsoft.com/download/3/E/1/3E1C3F21-ECDB-4869-8368-6DEBA77B919F/kagglecatsanddogs_5340.zip\n",
            "Resolving download.microsoft.com (download.microsoft.com)... 23.192.208.155, 2600:1409:12:2b7::317f, 2600:1409:12:299::317f\n",
            "Connecting to download.microsoft.com (download.microsoft.com)|23.192.208.155|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 824887076 (787M) [application/octet-stream]\n",
            "Saving to: ‘kagglecatsanddogs_5340.zip’\n",
            "\n",
            "kagglecatsanddogs_5 100%[===================>] 786.67M   113MB/s    in 7.6s    \n",
            "\n",
            "2024-12-21 21:47:42 (104 MB/s) - ‘kagglecatsanddogs_5340.zip’ saved [824887076/824887076]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import zipfile\n",
        "\n",
        "# Caminho para o arquivo ZIP\n",
        "zip_file_path = '/content/kagglecatsanddogs_5340.zip'\n",
        "\n",
        "# Caminho onde o conteúdo será descompactado\n",
        "extract_path = '/content/PetImages/PetImages'\n",
        "\n",
        "# Descompactar o arquivo\n",
        "with zipfile.ZipFile(zip_file_path, 'r') as zip_ref:\n",
        "    zip_ref.extractall(extract_path)\n",
        "\n",
        "print(\"Arquivo descompactado com sucesso!\")\n"
      ],
      "metadata": {
        "id": "J_hXxEJRBY6k",
        "outputId": "2986c611-1315-40de-99a6-4ac72d5bb7fd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Arquivo descompactado com sucesso!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "# Listar diretórios e arquivos na pasta principal\n",
        "dataset_path = \"/content/PetImages/PetImages\"\n",
        "print(\"Conteúdo da pasta:\", os.listdir(dataset_path))\n"
      ],
      "metadata": {
        "id": "rKivyrn7B_hu",
        "outputId": "28cd3f33-3341-41a6-82fd-f6da72bf26d9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Conteúdo da pasta: ['Dog', 'Cat']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Verificar a quantidade de arquivos em cada subpasta\n",
        "cats_dir = os.path.join(dataset_path, \"Cat\")\n",
        "dogs_dir = os.path.join(dataset_path, \"Dog\")\n",
        "\n",
        "print(\"Número de imagens em 'Cat':\", len(os.listdir(cats_dir)))\n",
        "print(\"Número de imagens em 'Dog':\", len(os.listdir(dogs_dir)))\n"
      ],
      "metadata": {
        "id": "AgXAQhjbB8K4",
        "outputId": "c378fb2c-f6b2-4503-babe-511a74df480b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Número de imagens em 'Cat': 12501\n",
            "Número de imagens em 'Dog': 12501\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Removendo possíveis arquivos corrompidos\n",
        "from PIL import Image\n",
        "\n",
        "def remove_corrupted_images(folder_path):\n",
        "    for file_name in os.listdir(folder_path):\n",
        "        file_path = os.path.join(folder_path, file_name)\n",
        "        try:\n",
        "            with Image.open(file_path) as img:\n",
        "                img.verify()  # Verifica se o arquivo é válido\n",
        "        except (IOError, SyntaxError):\n",
        "            print(\"Arquivo corrompido removido:\", file_path)\n",
        "            os.remove(file_path)\n",
        "\n",
        "# Remover imagens corrompidas de ambas as pastas\n",
        "remove_corrupted_images(cats_dir)\n",
        "remove_corrupted_images(dogs_dir)\n"
      ],
      "metadata": {
        "id": "MTurm_bpBzNt",
        "outputId": "aa897fda-8475-4f20-b967-2b6c4d0a5e85",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Arquivo corrompido removido: /content/PetImages/PetImages/Cat/666.jpg\n",
            "Arquivo corrompido removido: /content/PetImages/PetImages/Cat/Thumbs.db\n",
            "Arquivo corrompido removido: /content/PetImages/PetImages/Dog/Thumbs.db\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/PIL/TiffImagePlugin.py:935: UserWarning: Truncated File Read\n",
            "  warnings.warn(str(msg))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Arquivo corrompido removido: /content/PetImages/PetImages/Dog/11702.jpg\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import shutil\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Criar diretórios para treino e validação\n",
        "base_dir = \"/content/cats_dogs\"\n",
        "train_dir = os.path.join(base_dir, \"train\")\n",
        "validation_dir = os.path.join(base_dir, \"validation\")\n",
        "\n",
        "os.makedirs(os.path.join(train_dir, \"cats\"), exist_ok=True)\n",
        "os.makedirs(os.path.join(train_dir, \"dogs\"), exist_ok=True)\n",
        "os.makedirs(os.path.join(validation_dir, \"cats\"), exist_ok=True)\n",
        "os.makedirs(os.path.join(validation_dir, \"dogs\"), exist_ok=True)\n",
        "\n",
        "# Dividir os dados e copiá-los para os diretórios\n",
        "def split_data(src_dir, train_dst, val_dst, split_ratio=0.8):\n",
        "    files = [os.path.join(src_dir, f) for f in os.listdir(src_dir) if f.endswith(('.jpg', '.png'))]\n",
        "    train_files, val_files = train_test_split(files, test_size=1-split_ratio)\n",
        "    for file in train_files:\n",
        "        shutil.copy(file, train_dst)\n",
        "    for file in val_files:\n",
        "        shutil.copy(file, val_dst)\n",
        "\n",
        "# Organizar os dados\n",
        "split_data(cats_dir, os.path.join(train_dir, \"cats\"), os.path.join(validation_dir, \"cats\"))\n",
        "split_data(dogs_dir, os.path.join(train_dir, \"dogs\"), os.path.join(validation_dir, \"dogs\"))\n"
      ],
      "metadata": {
        "id": "WUUlw9ktClH-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Imagens de treino - gatos:\", len(os.listdir(os.path.join(train_dir, \"cats\"))))\n",
        "print(\"Imagens de treino - cachorros:\", len(os.listdir(os.path.join(train_dir, \"dogs\"))))\n",
        "print(\"Imagens de validação - gatos:\", len(os.listdir(os.path.join(validation_dir, \"cats\"))))\n",
        "print(\"Imagens de validação - cachorros:\", len(os.listdir(os.path.join(validation_dir, \"dogs\"))))\n"
      ],
      "metadata": {
        "id": "oeC0YgeHCsPJ",
        "outputId": "20891fb7-b12e-4a0b-97ce-2efc3a0c2271",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Imagens de treino - gatos: 9999\n",
            "Imagens de treino - cachorros: 9999\n",
            "Imagens de validação - gatos: 2500\n",
            "Imagens de validação - cachorros: 2500\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "# Criar geradores de treino e validação\n",
        "train_datagen = ImageDataGenerator(rescale=1.0/255)\n",
        "validation_datagen = ImageDataGenerator(rescale=1.0/255)\n",
        "\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "    train_dir,\n",
        "    target_size=(150, 150),\n",
        "    batch_size=32,\n",
        "    class_mode=\"binary\"\n",
        ")\n",
        "\n",
        "validation_generator = validation_datagen.flow_from_directory(\n",
        "    validation_dir,\n",
        "    target_size=(150, 150),\n",
        "    batch_size=32,\n",
        "    class_mode=\"binary\"\n",
        ")\n"
      ],
      "metadata": {
        "id": "9AzbzlWmCvFy",
        "outputId": "7c677300-c0d8-4a50-e095-1c819ea7590a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 19998 images belonging to 2 classes.\n",
            "Found 5000 images belonging to 2 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras import layers, models\n",
        "from tensorflow.keras.applications import MobileNetV2\n",
        "\n",
        "# Carregar o modelo MobileNetV2 pré-treinado, excluindo a parte superior (camadas finais)\n",
        "base_model = MobileNetV2(weights='imagenet', include_top=False, input_shape=(150, 150, 3))\n",
        "\n",
        "# Congelar as camadas do modelo base para não treinar essas camadas\n",
        "base_model.trainable = False\n",
        "\n",
        "# Construir o modelo\n",
        "model = models.Sequential([\n",
        "    base_model,\n",
        "    layers.GlobalAveragePooling2D(),\n",
        "    layers.Dense(1, activation='sigmoid')  # Apenas uma saída (gato ou cachorro)\n",
        "])\n",
        "\n",
        "# Compilar o modelo\n",
        "model.compile(optimizer='adam',\n",
        "              loss='binary_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Resumo do modelo\n",
        "model.summary()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 344
        },
        "id": "ldsRiSuVMlSV",
        "outputId": "12d6f18a-4e8f-4d9e-d5ba-ab1af7ed46df"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-14-222e4d8b479b>:5: UserWarning: `input_shape` is undefined or non-square, or `rows` is not in [96, 128, 160, 192, 224]. Weights for input shape (224, 224) will be loaded as the default.\n",
            "  base_model = MobileNetV2(weights='imagenet', include_top=False, input_shape=(150, 150, 3))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/mobilenet_v2/mobilenet_v2_weights_tf_dim_ordering_tf_kernels_1.0_224_no_top.h5\n",
            "\u001b[1m9406464/9406464\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ mobilenetv2_1.00_224 (\u001b[38;5;33mFunctional\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m, \u001b[38;5;34m5\u001b[0m, \u001b[38;5;34m1280\u001b[0m)          │       \u001b[38;5;34m2,257,984\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ global_average_pooling2d             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1280\u001b[0m)                │               \u001b[38;5;34m0\u001b[0m │\n",
              "│ (\u001b[38;5;33mGlobalAveragePooling2D\u001b[0m)             │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense (\u001b[38;5;33mDense\u001b[0m)                        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)                   │           \u001b[38;5;34m1,281\u001b[0m │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ mobilenetv2_1.00_224 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Functional</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1280</span>)          │       <span style=\"color: #00af00; text-decoration-color: #00af00\">2,257,984</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ global_average_pooling2d             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1280</span>)                │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePooling2D</span>)             │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                   │           <span style=\"color: #00af00; text-decoration-color: #00af00\">1,281</span> │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m2,259,265\u001b[0m (8.62 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,259,265</span> (8.62 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m1,281\u001b[0m (5.00 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,281</span> (5.00 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m2,257,984\u001b[0m (8.61 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,257,984</span> (8.61 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(\n",
        "    train_generator,\n",
        "    epochs=10,\n",
        "    validation_data=validation_generator\n",
        ")\n"
      ],
      "metadata": {
        "id": "l9qr4vexCw8Y",
        "outputId": "83c40d26-d52b-4b39-fbe9-b7661013e158",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m491s\u001b[0m 784ms/step - accuracy: 0.9790 - loss: 0.0542 - val_accuracy: 0.9628 - val_loss: 0.1043\n",
            "Epoch 2/10\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m492s\u001b[0m 787ms/step - accuracy: 0.9800 - loss: 0.0513 - val_accuracy: 0.9554 - val_loss: 0.1160\n",
            "Epoch 3/10\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m501s\u001b[0m 785ms/step - accuracy: 0.9795 - loss: 0.0550 - val_accuracy: 0.9596 - val_loss: 0.1079\n",
            "Epoch 4/10\n",
            "\u001b[1m318/625\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m3:16\u001b[0m 639ms/step - accuracy: 0.9803 - loss: 0.0558"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.preprocessing import image\n",
        "import numpy as np\n",
        "\n",
        "# Caminho para a imagem que você quer testar\n",
        "img_path = '/content/caminho/para/a/imagem.jpg'\n",
        "\n",
        "# Carregar a imagem, redimensionando para 150x150 pixels (o tamanho que o modelo espera, mas depende do modelo)\n",
        "img = image.load_img(img_path, target_size=(150, 150))\n",
        "\n",
        "# Converter a imagem para um array NumPy e normalizar (escalar os valores de 0 a 1)\n",
        "img_array = image.img_to_array(img) / 255.0\n",
        "\n",
        "# Adiciona uma dimensão extra para representar o batch (modelo espera um batch, mesmo que tenha só uma imagem)\n",
        "img_array = np.expand_dims(img_array, axis=0)\n",
        "\n",
        "print(img_array.shape)  # Verifica o formato da imagem\n"
      ],
      "metadata": {
        "id": "nr6YFwsnK3zs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Fazer a predição com o modelo\n",
        "prediction = model.predict(img_array)\n",
        "\n",
        "# A predição será um valor entre 0 e 1, onde valores próximos de 0 indicam \"gato\" e próximos de 1 indicam \"cachorro\"\n",
        "if prediction < 0.5:\n",
        "    print(\"A imagem é um Gato!\")\n",
        "else:\n",
        "    print(\"A imagem é um Cachorro!\")\n"
      ],
      "metadata": {
        "id": "O-_Iq0skK8Hu"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}